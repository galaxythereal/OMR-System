# -*- coding: utf-8 -*-
"""Buble_sheet .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1usSRiECKoCXoOxNoKzYO7v7o2lMU4qmC
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
    import cv2
    from google.colab.patches import cv2_imshow # Import the necessary function for image display in Colab
    import utlis
    ########################################################################
    webCamFeed = True
    pathImage = "/content/2.jpg"
    cap = cv2.VideoCapture(1)
    cap.set(10,160)
    heightImg = 700
    widthImg  = 700
    questions=5
    choices=5
    model_path = '/content/drive/MyDrive/image processing/best_model.keras' # Replace with the path to your model
    ans= [1,2,0,2,4]
    ########################################################################
    img = cv2.imread(pathImage)
    img = cv2.resize(img, (widthImg, heightImg)) # RESIZE IMAGE
    imgFinal = img.copy()
    imgBlank = np.zeros((heightImg,widthImg, 3), np.uint8) # CREATE A BLANK IMAGE FOR TESTING DEBUGGING IF REQUIRED
    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # CONVERT IMAGE TO GRAY SCALE
    imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1) # ADD GAUSSIAN BLUR
    imgCanny = cv2.Canny(imgBlur,10,70) # APPLY CANNY


        ## FIND ALL COUNTOURS
    imgContours = img.copy() # COPY IMAGE FOR DISPLAY PURPOSES
    imgBigContour = img.copy() # COPY IMAGE FOR DISPLAY PURPOSES
    contours, hierarchy = cv2.findContours(imgCanny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE) # FIND ALL CONTOURS
    cv2.drawContours(imgContours, contours, -1, (0, 255, 0), 10) # DRAW ALL DETECTED CONTOURS
    rectCon = utlis.rectContour(contours) # FILTER FOR RECTANGLE CONTOURS
    biggestPoints= utlis.getCornerPoints(rectCon[0]) # GET CORNER POINTS OF THE BIGGEST RECTANGLE
    gradePoints = utlis.getCornerPoints(rectCon[1]) # GET CORNER POINTS OF THE SECOND BIGGEST RECTANGLE


    if biggestPoints.size != 0 and gradePoints.size != 0:

            # BIGGEST RECTANGLE WARPING
            biggestPoints=utlis.reorder(biggestPoints) # REORDER FOR WARPING
            cv2.drawContours(imgBigContour, biggestPoints, -1, (0, 255, 0), 20) # DRAW THE BIGGEST CONTOUR
            pts1 = np.float32(biggestPoints) # PREPARE POINTS FOR WARP
            pts2 = np.float32([[0, 0],[widthImg, 0], [0, heightImg],[widthImg, heightImg]]) # PREPARE POINTS FOR WARP
            matrix = cv2.getPerspectiveTransform(pts1, pts2) # GET TRANSFORMATION MATRIX
            imgWarpColored = cv2.warpPerspective(img, matrix, (widthImg, heightImg)) # APPLY WARP PERSPECTIVE

            # SECOND BIGGEST RECTANGLE WARPING
            cv2.drawContours(imgBigContour, gradePoints, -1, (255, 0, 0), 20) # DRAW THE BIGGEST CONTOUR
            gradePoints = utlis.reorder(gradePoints) # REORDER FOR WARPING
            ptsG1 = np.float32(gradePoints)  # PREPARE POINTS FOR WARP
            ptsG2 = np.float32([[0, 0], [325, 0], [0, 150], [325, 150]])  # PREPARE POINTS FOR WARP
            matrixG = cv2.getPerspectiveTransform(ptsG1, ptsG2)# GET TRANSFORMATION MATRIX
            imgGradeDisplay = cv2.warpPerspective(img, matrixG, (325, 150)) # APPLY WARP PERSPECTIVE

            # APPLY THRESHOLD
            imgWarpGray = cv2.cvtColor(imgWarpColored,cv2.COLOR_BGR2GRAY) # CONVERT TO GRAYSCALE
            imgThresh = cv2.threshold(imgWarpGray, 170, 255,cv2.THRESH_BINARY_INV )[1] # APPLY THRESHOLD AND INVERSE

            boxes = utlis.splitBoxes(imgThresh) # GET INDIVIDUAL BOXES
            cv2_imshow( boxes[3])
            myPixelVal = np.zeros((questions, choices), dtype=int)
            countR = 0
            countC = 0
            # Use for instead of map so that we can use cv2_imshow function
            for image in boxes:
                #cv2_imshow(image) # Commented out because its only used for debug
                filled_not = classify_image(image, model_path)
                #print(f"Classification result: {filled_not}") # Commented out because its only used for debug
                myPixelVal[countR][countC] = filled_not
                countC += 1
                if (countC == choices):
                    countC = 0
                    countR += 1
            print(myPixelVal)

            # Vectorize the logic for finding user answers
            myIndex = np.argmax(myPixelVal, axis=1)
            print("USER ANSWERS", myIndex)

            # Vectorize the logic for validating the answers
            grading = np.equal(ans, myIndex).astype(int)
            print("GRADING", grading)
            score = (np.sum(grading) / questions) * 100  # FIND THE SCORE
            print("SCORE", score)

            # DISPLAYING ANSWERS
            utlis.showAnswers(imgWarpColored,myIndex,grading,ans) # DRAW DETECTED ANSWERS
            utlis.drawGrid(imgWarpColored) # DRAW GRID
            imgRawDrawings = np.zeros_like(imgWarpColored) # NEW BLANK IMAGE WITH WARP IMAGE SIZE
            utlis.showAnswers(imgRawDrawings, myIndex, grading, ans) # DRAW ON NEW IMAGE
            invMatrix = cv2.getPerspectiveTransform(pts2, pts1) # INVERSE TRANSFORMATION MATRIX
            imgInvWarp = cv2.warpPerspective(imgRawDrawings, invMatrix, (widthImg, heightImg)) # INV IMAGE WARP

            # DISPLAY GRADE
            imgRawGrade = np.zeros_like(imgGradeDisplay,np.uint8) # NEW BLANK IMAGE WITH GRADE AREA SIZE
            cv2.putText(imgRawGrade,str(int(score))+"%",(70,100)
                        ,cv2.FONT_HERSHEY_COMPLEX,3,(0,255,255),3) # ADD THE GRADE TO NEW IMAGE
            invMatrixG = cv2.getPerspectiveTransform(ptsG2, ptsG1) # INVERSE TRANSFORMATION MATRIX
            imgInvGradeDisplay = cv2.warpPerspective(imgRawGrade, invMatrixG, (widthImg, heightImg)) # INV IMAGE WARP

            # SHOW ANSWERS AND GRADE ON FINAL IMAGE
            imgFinal = cv2.addWeighted(imgFinal, 1, imgInvWarp, 1,0)
            imgFinal = cv2.addWeighted(imgFinal, 1, imgInvGradeDisplay, 1,0)

            # IMAGE ARRAY FOR DISPLAY
            imageArray = ([img,imgGray,imgCanny,imgContours],
                          [imgBigContour,imgThresh,imgWarpColored,imgFinal])
            cv2_imshow( imgFinal)


    # LABELS FOR DISPLAY
    lables = [["Original","Gray","Edges","Contours"],
              ["Biggest Contour","Threshold","Warpped","Final"]]

    stackedImage = utlis.stackImages(imageArray,0.5,lables)
    cv2_imshow(stackedImage)

    # SAVE IMAGE WHEN 's' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('s'):
        cv2.imwrite("Scanned/myImage"+str(count)+".jpg",imgFinal)
        cv2.rectangle(stackedImage, ((int(stackedImage.shape[1] / 2) - 230), int(stackedImage.shape[0] / 2) + 50),
                      (1100, 350), (0, 255, 0), cv2.FILLED)
        cv2.putText(stackedImage, "Scan Saved", (int(stackedImage.shape[1] / 2) - 200, int(stackedImage.shape[0] / 2)),
                    cv2.FONT_HERSHEY_DUPLEX, 3, (0, 0, 255), 5, cv2.LINE_AA)
        cv2_imshow( stackedImage)
        cv2.waitKey(300)
        count += 1

import numpy as np
import cv2
from google.colab.patches import cv2_imshow # Import the necessary function for image display in Colab
import utlis
########################################################################
webCamFeed = True
pathImage = "/content/2.jpg"
cap = cv2.VideoCapture(1)
cap.set(10,160)
heightImg = 800
widthImg  = 800
questions=5
choices=5
model_path = 'best_model.keras' # Replace with the path to your model
ans= [1,2,0,2,4]
########################################################################
img = cv2.imread(pathImage)
height, width = img.shape[:2]
#img=img[int(height*0.45):, :]
# Preprocessing
img = cv2.resize(img, (widthImg, heightImg))
imgCountours = img.copy()
imgFinal = img.copy()
imgBigContour = img.copy()
imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1)
imgCanny = cv2.Canny(imgBlur, 10, 70)
imgBlank = np.zeros_like(img)

## FIND ALL COUNTOURS
contours, hierarchy = cv2.findContours(imgCanny, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
cv2.drawContours(imgCountours, contours, -1, (255, 0, 0), 3)
rectCon = utlis.rectContour(contours) # FILTER FOR RECTANGLE CONTOURS
biggestContour = utlis.getCornerPoints(rectCon[0])
biggestPoints= utlis.getCornerPoints(rectCon[0]) # GET CORNER POINTS OF THE BIGGEST RECTANGLE

if biggestPoints.size != 0 :

  # BIGGEST RECTANGLE WARPING
  biggestPoints=utlis.reorder(biggestContour) # REORDER FOR WARPING
  cv2.drawContours(imgBigContour, biggestPoints, -1, (0, 255, 0), 20) # DRAW THE BIGGEST CONTOUR
  pts1 = np.float32(biggestPoints) # PREPARE POINTS FOR WARP
  pts2 = np.float32([[0, 0],[widthImg, 0], [0, heightImg],[widthImg, heightImg]]) # PREPARE POINTS FOR WARP
  matrix = cv2.getPerspectiveTransform(pts1, pts2) # GET TRANSFORMATION MATRIX
  imgWarpColored = cv2.warpPerspective(img, matrix, (widthImg, heightImg)) # APPLY WARP PERSPECTIVE
  # APPLY THRESHOLD
  imgWarpGray = cv2.cvtColor(imgWarpColored,cv2.COLOR_BGR2GRAY) # CONVERT TO GRAYSCALE
  imgThresh = cv2.threshold(imgWarpGray, 170, 255,cv2.THRESH_BINARY_INV )[1] # APPLY THRESHOLD AND INVERSE


  boxes = utlis.splitBoxes(imgThresh) # GET INDIVIDUAL BOXES

  cv2_imshow(boxes[10]) # Use cv2_imshow instead of cv2.imshow
  cv2_imshow( boxes[3])
  countR=0
  countC=0
  # Assuming you have the 'boxes' array after splitting the image

  boxes = utlis.splitBoxes(imgThresh) # GET INDIVIDUAL BOXES
  myPixelVal = np.zeros((questions, choices), dtype=int)
  countR = 0
  countC = 0
  # Use for instead of map so that we can use cv2_imshow function
  for image in boxes:
      cv2_imshow(image) # Commented out because its only used for debug
      filled_not = classify_image(image, model_path)
      print(f"Classification result: {filled_not}") # Commented out because its only used for debug
      myPixelVal[countR][countC] = filled_not
      countC += 1
      if (countC == choices):
          countC = 0
          countR += 1
  print(myPixelVal)

  # Vectorize the logic for finding user answers
  myIndex = np.argmax(myPixelVal, axis=1)
  print("USER ANSWERS", myIndex)

  # Vectorize the logic for validating the answers
  grading = np.equal(ans, myIndex).astype(int)
  print("GRADING", grading)
  score = (np.sum(grading) / questions) * 100  # FIND THE SCORE
  print("SCORE", score)

imageArray = ([img, imgBlur,imgGray,imgCanny],
 [imgCountours,imgBigContour,imgWarpColored,imgThresh],
              [imgBlank,imgBlank,imgBlank,imgBlank])
stackedImage = utlis.stackImages(imageArray, 0.5)
cv2_imshow(stackedImage) # Use cv2_imshow instead of cv2.imshow
cv2.waitKey(0)

import tensorflow as tf
import os
from tensorflow.keras import layers, models, optimizers
from tensorflow.keras.callbacks import ModelCheckpoint

# Define the model
def create_model(image_size=(256, 256), num_classes=2):
        model = models.Sequential([
            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(64, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Conv2D(128, (3, 3), activation='relu'),
            layers.MaxPooling2D((2, 2)),
            layers.Flatten(),
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.5),
            layers.Dense(num_classes, activation='softmax')
        ])
        return model
# Create a simple CNN model
model = create_model()

# Compile the model
model.compile(optimizer=optimizers.Adam(),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Define callbacks for model saving and early stopping
checkpoint = ModelCheckpoint('best_model.keras', # Changed .h5 to .keras
                             monitor='val_loss',
                             save_best_only=True,
                             mode='min')

# Training parameters
epochs = 20
batch_size = 16

# Load the data
data_dir = "/content/drive/MyDrive/image processing/omr_data"
image_size = (256, 256)

dataset = tf.keras.utils.image_dataset_from_directory(
    data_dir,
    labels='inferred',
    label_mode='int',
    image_size=image_size,
    batch_size=batch_size,
    shuffle=True
)


# Split the dataset
def split_dataset(dataset, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):

    if train_ratio + val_ratio + test_ratio != 1.0:
         raise ValueError("The sum of train, val, and test ratios must be 1.0")

    dataset_size = len(dataset)
    train_size = int(train_ratio * dataset_size)
    val_size = int(val_ratio * dataset_size)
    test_size = dataset_size - train_size - val_size


    train_ds = dataset.take(train_size)
    val_ds = dataset.skip(train_size).take(val_size)
    test_ds = dataset.skip(train_size + val_size).take(test_size)

    return train_ds, val_ds, test_ds

train_ds, val_ds, test_ds = split_dataset(dataset, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1)

# Apply caching to all datasets:
train_ds = train_ds.cache()
val_ds = val_ds.cache()
test_ds = test_ds.cache()


def augment_image(image, label):

    image = tf.image.random_flip_left_right(image)
    image = tf.image.random_flip_up_down(image)
    image = tf.image.random_brightness(image, max_delta=0.3)
    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)
    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)

    return image, label

# Apply data augmentation to the training dataset
train_ds = train_ds.map(augment_image)


# Train the model
history = model.fit(train_ds,
                      validation_data=val_ds,
                      epochs=epochs,
                      batch_size = batch_size,
                      callbacks=[checkpoint])

# Load the best model
best_model = tf.keras.models.load_model('best_model.keras') # Changed .h5 to .keras

# Evaluate the best model on the test set
loss, accuracy = best_model.evaluate(test_ds)
print(f"Test loss: {loss}")
print(f"Test accuracy: {accuracy}")

import tensorflow as tf
import numpy as np

def classify_image(image, model_path, target_size=(256, 256)):


    # Load the saved model
    model = tf.keras.models.load_model(model_path)

    # Add channels dimension if needed
    if len(image.shape) == 2:
      image = np.expand_dims(image, axis=-1)  # Make it (H, W, 1)

    # Convert to 3 channels if needed
    if image.shape[-1] != 3:
        image = np.concatenate([image, image, image], axis=-1)  # Make it (H, W, 3)

    # Resize the image
    img = tf.image.resize(image, target_size)
    img_array = np.array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

    # Predict the class of the image
    prediction = model.predict(img_array)
    class_index = np.argmax(prediction)

    return class_index

import tensorflow as tf
import numpy as np
def classify_image(image_path, model_path, target_size=(256, 256)):

    # Load the saved model
    model = tf.keras.models.load_model(model_path)

    # Load and preprocess the image
    img = tf.keras.utils.load_img(image_path, target_size=target_size)
    img_array = tf.keras.utils.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0) # Add batch dimension

    # Predict the class of the image
    prediction = model.predict(img_array)
    class_index = np.argmax(prediction)

    return class_index

# Example of usage:
if __name__ == '__main__':
  image_path = '/content/drive/MyDrive/image processing/omr_data/empty/box_21.png'  # Replace with the path to your test image
  model_path = 'best_model.keras' # Replace with the path to your model

  result = classify_image(image_path, model_path)
  print(f"Classification result: {result}") # Returns 0 or 1

  image_path = '/content/drive/MyDrive/image processing/omr_data/filled/box_18.png'  # Replace with the path to your test image
  result = classify_image(image_path, model_path)
  print(f"Classification result: {result}")

import os

output_folder = "/content/boxes2"
os.makedirs(output_folder, exist_ok=True)
if biggestPoints.size != 0:
    # BIGGEST RECTANGLE WARPING
    biggestPoints = utlis.reorder(biggestContour)  # REORDER FOR WARPING
    cv2.drawContours(imgBigContour, biggestPoints, -1, (0, 255, 0), 20)  # DRAW THE BIGGEST CONTOUR
    pts1 = np.float32(biggestPoints)  # PREPARE POINTS FOR WARP
    pts2 = np.float32([[0, 0], [widthImg, 0], [0, heightImg], [widthImg, heightImg]])  # PREPARE POINTS FOR WARP
    matrix = cv2.getPerspectiveTransform(pts1, pts2)  # GET TRANSFORMATION MATRIX
    imgWarpColored = cv2.warpPerspective(img, matrix, (widthImg, heightImg))  # APPLY WARP PERSPECTIVE

    # APPLY THRESHOLD
    imgWarpGray = cv2.cvtColor(imgWarpColored, cv2.COLOR_BGR2GRAY)  # CONVERT TO GRAYSCALE
    imgThresh = cv2.threshold(imgWarpGray, 170, 255, cv2.THRESH_BINARY_INV)[1]  # APPLY THRESHOLD AND INVERSE

    boxes = utlis.splitBoxes(imgThresh)  # GET INDIVIDUAL BOXES

    # حفظ كل مربع داخل الفولدر
    for i, box in enumerate(boxes):
        file_path = os.path.join(output_folder, f"box_{i + 25}.png")
        cv2.imwrite(file_path, box)
        print(f"Saved box {i + 25} at {file_path}")

    print("All boxes have been saved successfully!")